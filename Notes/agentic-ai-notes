# Intro
- Agent anatomy can be broken down into 3 main parts
	- Model (the brain)
	- Tools (the hands)
	- Orchestration (the conductor)
- General flow of agent:
	- the model reasons about which tool is needed for the next step in the process, and the orchestration layer actually calls that tool
	- the result (the observation) from that tool call is then fed back into the model for future thought cycles

- Model (LLM)
	- key function: managing the context window
	- constantly deciding what's important
	- information comes from the mission, memory, what the tools just did
	- the model curates the input context window of the LM
- Tools
	- the connection to the outside world
	- APIs, databases, vector stores, code functions
- Orchestration
	- manages the operational loop
	- keeps track of memory or state
	- manages the reasoning strategy (like chain of thought or ReAct)
	- ReAct: thinking, acting, observing, then cycle
- Deployment
	- hosting the agent on a secure, scalable server
	- integrating it with tools to make it production ready like monitoring, logging and management
	- once deployed, can be accessed by users through a frontend or via an Agent to Agent (A2A) API

- if traditional development is like "bricklaying", agentic development is like "directing" or "conducting"
- an LM's greatest strength being it's flexibility to do *anything* is often an agentic system's greatest weakness, because you are forcing it to do one specific thing
- Agents are software which manage the inputs of LMs to get work done
- In essence, an agent is a system dedicated to the art of **what to include in the context window**. The context can include system instructions, user input, session history, long term memories, grounding knowledge from authoritative sources, tools to be used, results of tools already invoked, etc.
- The sophisticated management of the model's attention allows its reasoning capabilities to problem solve for novel circumstances and accomplish objectives

## The Agentic Problem-Solving Process

What are the specific steps an Agent takes to accomplish it's mission?

1. Get the Mission
	- can be provided by user prompt
	- can be provided through automated trigger
2. Scan the Scene
	- this step involves gathering context from the environment
	- more technically, this means the orchestration layer accessing its available resources
	- ex questions:
		- "What does the user's request
		say?", "What information is in my term memory? Did I already try to do this task? Did the
		user give me guidance last week?", "What can I access from my tools, like calendars,
		databases, or APIs?"
3. Think it Through
	- The model assess it's mission against the available tools and context and comes up with a plan of action
	- this plan of action is often a chain of reasoning involving sequential tool use
4. Take Action
	- Does the first concrete step of the plan (uses the first tool it needs to use)
5. Observe and Iterate
	- Observes the output of the tool use (action) and adds that output to the agent's context or memory
	- Uses that new context to go back to step 3 and repeats steps 3-5 until the mission is complete

# A Taxonomy of Agentic Systems

### Level 0 - Core Reasoning System
- LM operating in isolation without any tools or ways to access realtime data
- lack of any real-time awareness, blind to any event or fact outside its training data

### Level 1 -  Connected Problem-Solver
- LM connected to tools that can interact with it's environment
- Using 5-step loop defined above, the agent can answer more realtime questions and do more complex tasks

### Level 2 - Strategic Problem-Solver
- can strategically plan complex, multi-part goals
- new skill for this level: **context engineering**: the ability for the agent to select, package and include the most relevant and necessary context for the reasoning of the next step
- context engineering is very important for agent accuracy

### Level 3 - Collaborative Multi-Agent System
- Basically a team of level 2 agents, however with specific roles and specialties
- this model directly reflects a human organization, with divisions of labor
- usually has an orchestrator agent in charge of other agents that delegates tasks

### Level 4 - Self Evolving System
- A level 3 system, but the ability to edit and create new tools and agents that can serve a purpose that the system sees a need for
- moves from using a fixed set of resources to actively expanding them
- this is the current frontier of agentic systems

# Core Agent Architecture

How do we actually build an agent? We split it up into three distinct parts: Model, Tools, and Orchestration
## Model
- should not pic the model with the highest benchmark score -not necessarily the best pick model for the task at hand
- important agentic fundamentals for models are **superior reasoning and reliable tool use**
- start by defining the business problem, then test models against metrics that directly map to that outcome
- the "best" model is the one that sits at the optimal intersection of speed, quality and price for your specific task
- if you have a team of specialists approach, then use heavy reasoning models for initial planning and complex reasoning, then switch to a faster more cost effective model for high volume tasks like classifying user intent or summarizing basic test
- importantly, the AI landscape is constantly evolving
	- building for this reality means building a CI/CD pipeline that continuously evaluates new models against key business metrics, so that you can de-risk and accelerate upgrades to your product

## Tools
- a tool interface is a three-part loop
	- defining what a tool can do for the LM to read and reason with
	- invoking the tool itself
	- observing the result

#### Main types of tools agents use:

Retrieving Information: Grounding in Reality
- RAG for unstructured data
- Natural Language to SQL (NL2SQL)
	- allows agent to query databases to answer analytic questions about the data at hand
- These types of tools reduce hallucinations because the LM can be grounded in the real data that it uses as context

Executing Actions: Changing the World
- wrapping existing APIs and code functions as tools
- for more dynamic tasks, an agent can potentially write and execute code on the fly
	- such as SQL query or a python script
- this also includes tool for human interaction, like Human in the Loop (HiTL) frameworks
	- can pause workflow and ask user for confirmation
	- request information from a user through a user interface

#### Connecting Tools to Agents
- there are standards for creating "tools" that agents can use
- an example of a standard for tool use is the OpenAPI specification, giving the agent a structured contract that describes a tool's purpose, its required parameters and its expected response
- For simpler, easier discovery and connection to tools, MCP is the standard
- A few models have native tool use, such as Gemini with google search

## Orchestration
- central nervous system that connects the model to the tools
- this is the engine that runs the "think, act, observe loop"

#### Core Design Choices
1. Determining agent's degree of autonomy
	- on one end: deterministic workflows that call an LM as a tool for a specific task
	- on the other end: the LM is in driver's seat, constantly making decisions and executing tasks to achieve a goal
2. Implementation method
	- no code builders: speed and accessibility
	- code first frameworks: control, customizability, and integration

- regardless of approach, the framework should be
	- open - should be able to use any model without vendor lock in
	- controllable - the reasoning of the LM is constrained by business logic
	- observable - a framework that generates traces, logs and exposes reasoning

#### Instruct with Domain Knowledge and Persona
- most powerful step is to instruct the agent with domain knowledge and a distinct persona
- this is usually accomplished through a system prompt, telling the LM what role it is playing in the agent architecture - agent's constitution
	- provide constraints, desired output schema, rules of engagement, a specific tone of voice, and explicit guidance on when and why it should use its tools
	- example scenarios in the instructions/system prompt is usually very effective as well

#### Augment with Context
- agent memory is nothing but the added context to the LM context window at runtime
- short term memory
	- agent's active scratchpad
	- maintaining the running history of the current conversation
	- tracks sequence of Action, Observation pairs from the current loop, providing the immediate context for the model to decide what to do next
	- can be implemented as state, artifacts, sessions or threads
- long term memory
	- persistence **across** sessions
	- architecturally this is almost always implemented as a RAG
	- the orchestrator gives the agent the ability to query it's own history, including user preferences or conversations it's had with a user a few weeks ago

#### Multi Agent Systems and Design Patterns
- Coordinator pattern
	- introduces a manager agent that analyzes a complex request, segments the primary task and routes each subtask to the appropriate specialist agent
	- coordinator then aggregates result into the required output schema
- Sequential pattern
	- acts as a digital assembly line where the output of one agent becomes the input of another agent
- Iterative Refinement pattern
	- creates a feedback loop with the generator agent to create content and the critic agent to evaluate it against quality standards
- Human in the loop pattern
	- creates deliberate pauses in the workflow to get human approval before an agent takes a significant action

## Agent Deployment and Services
- can deploy an agent specific deployment options like vertex AI Agent Engine
- or can deploy to a legacy traditional deployment runtimes in a docker container like cloud run or gke
- for agents in production, you should always have CI/CD pipelines and automated testing for your agents

#### Agent Ops
- traditional unit tests don't work for agentic systems, especially because you cannot simply assert that the `output ==  expected`
- because language is complicated, it usually requires another LM to evaluate "quality" of the output with the input query or prompt
- Agent Ops is this new field that deals with the challenges of building, deploying and governing AI agents

#### Measure what matters
- ask yourself what are the KPIs (Key Performance Indicators) that prove the agent is doing what it is supposed to be doing?
- these KPIs should be the likes of
	- goal completion rates
	- task latency
	- user satisfaction scores
	- operational cost per intraction
	- impact on business goals such as revenue, conversion or customer retention
- these KPIs will guide testing, and make you do metrics driven development

#### Using an LM as judge
- creation of evaluation datasets should be built with these metrics
	- the dataset must cover the full range of use cases that you expect the user to engage with
	- along with all edge cases that the user can do to break the system
- eval results should always be reviewed by a domain expert before being accepted as valid
- the curation and maintenance of these evaluations is becoming a key responsibility for product managers with the support of Domain experts

#### Metrics-Driven Development
- once you have an automated evaluation suite, testing is simple
- just run the new version against the same evaluation golden dataset and compare the scores to the existing production version
- these scores should include latency, cost, and task success rates
- **important**: for max safety, do A/B deployments to slowly roll out new versions and compare real-world production metrics along with simulation scores such as user feedback and error reporting

#### Debug with OpenTelemetry Traces
- with traces you can see the exact prompt sent to the model, the model's internal reasoning, the specific tool it chose to call (if any), the parameters it generated for that tool, and the raw data that came back as an observation
- useful for debugging not for metrics
- traces can be collected platforms like google cloud trace, or langsmith

#### Cherish Human Feedback
- when a user files a bug report, save that real world edge case and add it to your automated eval scenarios
- close the loop by capturing the feedback, replicating the issue, and converting that scenario into a specific permanent test case in your evaluation dataset
- this ensures you fix the but also vaccinates the system against that entire class of error ever happening again

## Agent Interoperability
- agents are not tools, there's a difference between connecting to agents vs connecting agents with data and APIs
#### Agents and Humans
- most common form of agent-human interaction is a chatbot
	- user types in a request and agent acts a backend service, processes it and returns a block of text
	- can provide structured data, like JSON, to power rich, dynamic front-end experiences
	- human in the loop interaction patterns can include intent refinement, goal expansion, confirmation and clarification requests
- computer use is where the LM takes control of a user interface often with human interaction and oversight
- LM can change the UI to meet the needs of the moment
	- done with tools which control UI (MCP UI, AG UI, A2UI)
- live, real-time, multimodal communication also exists, to enable bidirectional streaming of users speaking to an agent and interrupting it, just as they would in a natural conversation

#### Agents and Agents
- core challenge is twofold
	- discovery - how does my agent find other agents and know what they can do?
	- communication - what is the standard of communication that both agents know they are going to speak?
- Agent2Agent (A2A) protocol
	- allows any agent to publish a digital "business card" known as an Agent Card
	- agent card = JSON file that has agent's capabilities, its network endpoint, and security credentials required to interact with it
	- agents communicate using a task-oriented architecture
		- a client agent sends a task request to a server agent, which then provides **streaming updates** as it works on the problem over a long-running connection

#### Agents and Money
- giving agents access to money and purchasing power is risky and there are complex issues relating to authorization, authenticity and accountability
- Agents Payments Protocol (AP2)
	- has cryptographically-signed digital mandates that act as proof of user intent
	- creates an audit trail for every transaction
- x402
	- open internet payment protocol that uses the HTTP 402 "payment required" status code

## Securing a Agent
- if you give LM power to do things, then they might do rogue actions or expose sensitive information to third parties
- best practice is hybrid defense in depth approach
	- first layer - traditional deterministic guardrails 
		- set of hardcoded rules that act as security chokepoint
		- ex: block any purchase more than a $100 
	- second layer - reasoning-based defenses
		- training the model to be more resilient to attacks
		- employing smaller specialized guard models that act like security analysts
- hybrid model ensures that there are two different types of guardrails always protecting from malicious attacks

#### Agent Identity
- each agent on the platform must be issued a secure agent identity, that has permissions, service accounts, and more
- once an agent has a cryptographically verifiable identity, it can be granted agent specific privileges
	- using standards like SPIFFE
- ensures that even if a single agent is compromised, its hard for any one agent to deal lasting damage to the system
- policies can ensure that principals that only need access to a certain permission has access to it
	- often done at the API governance layer, along with governance supporting MCP and A2A services

#### Securing an Agent in practice
- clear definition of identities - user account (OAuth), service account (to run code), agent identity (to use delegated authority)
- establish policies to constrain access to services
- build guardrails into tools, models and sub-agents to enforce policies
	- ensures that a tool or sub-agent's own logic will refuse to execute an unsafe action
- ADK provides callbacks and plugins
	- callback allows you to inspect the parameters of a tool before it runs
	- plugins allow you to use LM to screen user inputs and agent outputs for prompt injections or harmful content
- Model Armor
	- dedicated service that does all this

## Scaling up from a single agent to fleet of agents
- lots more security concerns with **agent sprawl**, the complex interactions between many agents, tools and users might cause more security vulnerabilities

#### Security and Privacy
- possible attacks include
	- prompt injection
	- data poisoning to corrupt the information it uses for training or RAG
- ensure that an enterprise proprietary information is never used to train base models
- requires input and output filtering
- contractual protections like intellectual property indemnity for training data and generated output

#### Agent Governance: A Control Plane instead of Sprawl
- creating a single point of contact (gateway) between agents, tools and users creates observability of every interaction
- this control plane serves two functions
	- runtime policy enforcement
		- handles authentication and authorization
		- common logs, metrics and traces for every transaction
	- centralized governance
		- to enforce policies, the gateway needs a source truth
		- provided by central registry that has all agentic assets with necessary permissions
		- allows for security reviews as well as creation of fine-grained policies that dictate which business units can access which agents

#### Cost and Reliability
- spectrum of infrastructure options for scale-to-zero applications as well as provisioned throughput LM services for always on uptimes
- choose well!

## Self Evolving Agents
- agent performance will degrade over time because policies, technologies and data formats are constantly changing
- manually updating a large fleet of agents is uneconomical and slow
- design agents that can learn autonomously, improving quality on the job

#### How agents learn and evolve
- learning process is fueled by:
	- Runtime Experience
		- Session logs, traces, and memory that captures successes, failures, tool interactions and decision trajectories.
		- this includes HiTL feedback which provides authoritative corrections and guidance
	- External Signals
		- new external documents such as updated policies, public regulatory guidelines, or critiques from other agents
- this information is used to optimize agent future behavior
- instead of summarizing past interactions, advances systems create generalizable artifacts to guide future tasks
	- Q: does this mean that the agent will edit it's own artifacts when it gets new information from an external source?
- successful adaptation techniques include:
	- enhanced context engineering
		- system refines it's prompts, few-shot examples (?) and information it retrieves from. memory
		- by optimizing context, increases success rate
	- tool optimization and creation
		- when the agent identifies gaps in its capabilities, it creates new tools on the fly by itself
- this can take shape in the form of a specified **learning agent** that observes entire interactions and sees corrective feedback from the human expert. it then generalizes this feedback into a new reusable guideline for other agents' artifacts or rules
- also look into RLHF - emerging field with great practical use cases

#### Agent Gym
- a dedicated space where agents can run in an offline environment with advanced tooling and capabilities
- not in the execution path - so can use any new and untested tools, features, models, etc.
- simulation environment, so the agent can "exercise" on new data and learn
- can call advanced synthetic data generators which guide the simulation to be as real as possible and pressure test the agent
- open to new tools and capabilities, doesn't need to be as strict and can explore open protocols in a more advanced setting
- can consult with human domain experts to guide the next set of optimizations

# Day 2

# Tools and Tool Calling

## What do we mean by tool?
- Two base types of tools:
	- Allows a model to know something (usually real time)
	- Allows a model to do something (update a db, calling an API, executing other code, etc.)
## Types of Tools
- tool definition declares a contract between the model and the tool
	- includes clear name, parameters, and a natural language description that explains its purpose and how it should be used
- Three types of tools explained below
### Function Tools
- Tools defined as functions with descriptions and contracts about tool usage - description is provided as part of the request context
- These are external functions that the model can call as needed
### Built-in Tools
- Some LMs have built-in tools, where tool definition is given to model implicitly
- Gemini API can use google search, code execution, computer use, url context
### Agent Tools
- an agent can also be invoked as a tool
- allows the primary agent to maintain control over the interaction
- primary agent processes the sub-agent input and output as necessary
## Taxonomy of Agent Tools
Another way to categorize agent tools by their primary function:
- Information Retrieval
	- structured and unstructured data
- Action/Execution
	- real world operations such as sending emails, posting messages, code execution, controlling physical devices
- System / API Integration
	- connecting with existing software systems and APIs
- Human in the loop
	- seek approval for critical actions
## Best Practices for Tool Use
### Documentation is important

Tool documentation (name, description and attributes) are all passed down to the model as part of request context, so important that tools are well documented. Here are some general guidelines:
- use clear names for function name, parameter names, etc
- describe all input and output parameters
	- required type of input and output parameters
	- how the tool will use the parameter
- simplify parameter lists to keep them as short as possible
- clarify tool descriptions
	- purpose of tool
	- any details to call the tool effectively
	- avoid shorthand or technical jargon
- add targeted examples
	- can also dynamically retrieve examples related to the immediate task to minimize context bloat
- provide default values for key parameters
	- document and describe the default values for these parameters in the tool documentation
### Describe actions, not implementations
- model's instructions should describe actions, not when to use specific tools
	- this is to make sure there is no conflict between the actual tool's instruction set and the model's instruction set - can confuse the LLM
	- this is also relevant when the list of available tools can change
- describe what, not how
	- say "create a big to describe the issue" instead of "use the `create_bug` tool to create the issue"
- don't duplicate instructions
	- don't repeat or restate tool instructions or documentation
	- can create an additional dependency between instructions and tool implementation - if tool changes has to update in two places instead of one
- don't dictate workflows
	- describe objective and let the model figure out which tool to use in what order autonomously
- DO explain tool interactions
	- if one tool use will affect another tool, document this and explain it to the model
	- `fetch_web_page` tool may store the retrieved web page in a file - document this somewhere so the agent knows how to access the data
### Publish tasks, not API calls
- tools shouldn't just be wrappers around basic API calls
- tools should instead reflect full end-to-end task workflow that the agent might need to perform
	- this makes it easier for the agent to know which tool to use
- APIs are meant for human developers who are building static workflows, so might have hundreds of possible parameters that influence API output.
- Tools for agents, however, are expected to be used dynamically and on the fly, so if a tool represents a specific task the agent should accomplish, it'll be much more accurate
### Make tools as granular as possible
- SRP - define a clear, single responsibility for each tool
- easier to document the tool and for the agent to know when to use it
- don't generally create multi-tools
	- these are complicated to document and maintain, and can be difficult for agents to use consistently
	- however, if there is a scenario where a common workflow requires many tool calls in a sequence, then it is ok to create that "multi-tool" as long as it is well documented
### Design for concise output
- don't return large responses
	- large tables, dictionaries, files or images can swamp the output context of an LLM
	- frequently stored in an agent's conversation history, can impact subsequent requests
- use external systems
	- if you do need to store large files somewhere, store them in a temp database table so a subsequent tool can retrieve the data directly
### Use validation effectively
- use schema validation for tool inputs and outputs whenever possible
- serve as further documentation of tool's capabilities and function
- provide a run-time check on the tool operation, allows the app itself to validate whether the tool is being called correctly
### Provide descriptive error messages
- the tool's error will also be passed to the LM as output
- so include descriptive error messages as well as future steps that the LM can take
	- ex: "No product data found for product ID XXX. Ask the customer to confirm the product name, and look up the product ID by name to confirm you have the correct ID."
# Model Context Protocol (MCP)

## Core Architectural Components: Hosts, Clients and Servers

**MCP Host**
- application responsible for creating and managing MCP clients
- enforces security policies and content guardrails

**MCP Client**
- the actual component within the host that maintains the connection with the MCP server
- issues commands, receives responses and manages the lifecycle of the communication session with the MCP server

**MCP Server**
- A program that provides a set of capabilities that the server dev wants to make available to AI applicationos
- functions as an adapter for an external tool, data source, or API
- in enterprise contexts, servers are also responsible for security, scalability and governance

## The Communication Layer: JSON-RPC, Transports, and Message Types
- Base Protocol: MCP uses JSON-RPC 2.0 as base message format
- Message Types:
	- Requests: RPC call that expects a response
	- Results: message containing the successful outcome to a corresponding request
	- Errors: A message indicating that a request failed, including a code and description
	- Notifications: A one-way message that cannot be replied to
- Transport Mechanisms
	- stdio
		- only for local communication
		- fast, direct communication where MCP server runs as sub-process of Host application
		- used when tools need to access local resources such as user's filesystem
	- streamable HTTP
		- recommended remote client-server protocol
		- allows stateless servers (standard), with stateful SSE streaming responses (deprecated)

## Key Primitives: Tools and others
- MCP defines several key concepts and entity types
- capabilities offered by server to client include Tools, Resources and Prompts
- capabilities offered by client to server included Sampling, Elicitation, and Roots
- only tools are 99% supported, most client applications don't support the other capabilities

### Tools
- The tool entity is a standardized way for server to describe a function it makes available to clients
- ex: read_file, get_weather, execute_sql, etc.
- MCP servers publish a list of their available tools with descriptions and parameter schemas for agents to discover
- Tool definitions must conform to a JSON schema with
	• name: Unique identifier for the tool
	• title: [OPTIONAL] human-readable name for display purposes
	• description: Human- (and LLM-) readable description of functionality
	• inputSchema: JSON schema defining expected tool parameters
	• outputSchema: [OPTIONAL]: JSON schema defining output structure
	• annotations: [OPTIONAL]: Properties describing tool behavior
- everything in the schema, even the optional things (except annotations), should be included and everything should be carefully worded
- annotations comprise "hints" that are hints on the MCP tool  behavior. These hints are just hints, and aren't promises of exact behavior
	• destructiveHint: May perform destructive updates (default: true).
	• idempotentHint: Calling repeatedly with the same arguments will have no additional
	effect (default: false).
	• openWorldHint: May interact with an "open world" of external entities (default: true).
	• readOnlyHint: Does not modify its environment (default: false)
	• title: Human-readable title for the tool (note that this is not required to agree with the
	title as provided in the tool definition).

Tool results can be whatever the MCP server wants
- can be structured, unstructured
- contain different content types
- can link to other resources on server
- can be returned as single response or stream of responses

Unstructured Content
- can be text, audio, image
- can return specified Resources, which can be a link to a entity stored at another URI, or embedded in tool result
- be cautious of retrieving or using resources returned from an MCP server in this way, should only use Resources from trusted servers

Structured Content
- always returned as a JSON object
- can use outputSchema to validate tool results

Error Handling:
- two standard error reporting mechanisms
	- can return standard JSON-RPC errors for protocol issues such as unknown tools, invalid arguments, etc
	- can return error messages in the tool results by setting the `"isError": true` parameter in the result object
		- usually for errors generated in the operation of the tool itself, like backend API failures, invalid data, business logic errors

### Resources
- server side capability intended to provide contextual data
- examples include log files, configuration data, market statistics, or structured blobs such as PDFs or images
### Prompts
- allows the server to provide reusable prompt examples or templates related to tools and resources
- MCP server can give it's clients a higher-level description of how to use the tools it provides
- there are a lot of security concerns with this
### Sampling
- server requests a client-side LLM call
- gives clients control over security, model type
- very useful for human in the loop frameworks where the user that is going through the client has to approve or reject something
- security risks for potential prompt injections
### Elicitation
- MCP server requests additional user info from the client
- queries the host application dynamically for additional data to complete the tool request
- security concerns once more - servers should not use elicitation to request sensitive information
- users/clients should be able to approve, decline or cancel the request
### Roots
- defines the boundaries of where the servers can operate within the client file system
- very little guardrails in the spec around the behavior of servers with respect to Roots

# Day 3

# Context Engineering
- outside LLM training data, their reasoning and awareness are confined to the information in the "context window" of a message/API call
- agents need instructions, actions, data and contextual conversational information for every task, for every message
- this assembly and management of information is Context engineering
- external systems like RAG databases, session stores and memory managers manage a lot of this context
	- agent framework in charge of orchestrating these systems to retrieve and assemble context
- goal of context engineering: ensure the model has no more and no less than the most relevant information to complete its task

payload to LM contains:
- context to guide reasoning
	- system instructions: agent persona, capabilities, constraints
	- tool definitions
	- few-shot examples
- evidential and factual data
	- Long-Term Memory: knowledge about the user or topic, gathered across multiple sessions
	- External Knowledge: information retrieved from db or docs, usually from RAG
	- Tool/Sub-agent Outputs: data returned from a tool or a sub-agent
	- artifacts: non-textual data (files, images) associated with the user or session
- Immediate conversational information
	- convo history
	- state / scratchpad / short-term memory: temporary in progress information the agent uses for its immediate reasoning
	- user prompt

- memories are not static - they must be retrieved and updated based on new user interactions or new data
- growing conversation history is hard to manage
	- latency and effectiveness can suffer
	- context rot - ability of LM to pay attention to critical information suffers due to ever growing context
	- strategies exist to mutate the hsitory (summarization, pruning, etc)

agent operational context loop:
![[Pasted image 20260107185922.png]]
- fetch context
	- retrieves context such as memories, RAG docs, recent conversation events
	- will use the user query and other metadata to figure out what information to retrieve
- prepare context
	- dynamically constructs the full prompt for the LM call
	- blocking, bottleneck process: agent cannot proceed until context is ready
- invoke LM and tools
	- calls LM and any necessary tools until a final user response is generated
	- tool and model output is appended to context
- upload context
	- new info is uploaded to persistent storage (long term memory)
# Sessions
- captures the immediate dialogue history and working memory for a single, continuous conversation
- sessions are tired to a specific user
- allows agent to maintain context and provide coherent responses within the bound of a single conversation
- a user can have multiple sessions, but each session is distinct to the LM

every session contains:
- events: chronological history of what happened
	- user input
	- agent response
	- tool call
	- tool output
- state: working memory/scratchpad
	- temporary structured data relevant to the current conversation

- as session progresses, agent will append additional events to the session
- may mutate the state based on logic in agent

- a production agent's execution environment is typically stateless
- convo history (events) must be saved to persistent storage to maintain continuous user experience
- db to store and manage sessions, there are solutions for this like Agent Engine Sessions
## Variance across frameworks and models
- different agent frameworks implement sessions, events and state in different ways
- agent frameworks are responsible for maintaining convo history and state for LLMs
- agent framework acts as a powerful abstraction for developers to work with
- framework handles mapping conversational data from the internal object (eg. an ADK Event) to the corresponding role and parts in a Content object for a list of Contents before making the API call behind the scenes
- Google ADK uses explicit Session object and explicit state object
- LangGraph has all encompassing state object that is mutable
## Sessions for multi agent systems
- multiple agents must share information
- session history is permanent, unabridged transcript of the entire conversation
- context is carefully crafted information payload sent to LLM for single turn
- this section focuses on what information is passed across agents, not what context is sent to the LM

two main ways to handle session history
- shared history where agents contribute to a single log
	- every agent's message, tool call and observation is appended to one central log in chronological order
	- best for tightly coupled, collaborative tasks requiring a single source of truth
	- ex: one agent output is direct input for next agent
	- linear, sequential workflows
- separate histories where each agent maintains its own perspective
	- internal processes such as intermediary thoughts, tool use, reasoning steps are kept within the agent's private log, not visible to others
	- communication occurs through explicit messages where agent shares final output, not process
	- implemented using Agent as a tool or Agent to Agent (A2A) protocol
		- Agent as a tool: one agent invokes another as if it were a standard tool, passing inputs and receiving a final output
		- A2A protocol: structured protocol for direct messaging
### Interoperability across multiple agent frameworks
- an agent built on one framework (google adk) cannot easily share or talk to agents built on other frameworks (langgraph) because of the complexity and differences in implementation
- possible solution: Agent-to-Agent (A2A) protocol
	- enables agents to exchange messages, but cannot share rich contextual state
- robust architectural pattern: abstracting shared knowledge into a framework-agnostic data layer, like Memory
- Memory layer doesn't have framework specific objects like Events and Messages, designed to hold processed information
- stored in abstract data structures like strings or dictionaries
### Production Considerations for Sessions

**Security and Privacy**
- strict isolation: most critical security principle
- a session is owned by a single user, one user can never access another user's session data
- every request to the session store must be authenticated and authorized against the session's owner
- PII should be redacted before session data is ever written to storage

**Data Integrity and Lifecycle Management**
- sessions should not live forever
- implement a Time-to-Live policy that automatically deletes inactive sessions
- operations appended to the session history must be in deterministic order (chronologically)

**Performance and Scalability**
- session data is on "hot path" of every user interaction - performance is primary concern
- agent runtime is stateless, session history retrieved from central db
- crucial to reduce the size of the data transferred - filter or compact the session history before agent gets it
### Managing long context conversations: tradeoffs and optimizations

Limitations for latency sensitive applications include
- Context window limits: max text it can process
- API costs: shorter convo histories means less tokens sent, less money used
- Latency: sending more text to the model takes longer ot process, slower response time
- Quality: as number of tokens increase, performance can get worse because of noise in the context

- managing a long conversation is a game of not adding too much and not adding too little, you need to adjust enough context where the agent has critical pieces of information without shoving in every piece of information that the model can have access to
- compaction strategies aim to do this by intelligently trimming the history while preserving the most important context

Compaction Strategies:
- Keep the last N turns: basic sliding window algo
- Token based truncation: counts the tokens in the messages and cuts off anything older than a defined max token count
- Recursive summarization: older parts of the conversation are replaced with AI-generated summary
	- the agent periodically summarizes the oldest messages, so that it has access to at least some form of the history
- important to do expensive operations like recursive summarization asynchronously, and persist the results
	- this way, client is not kept waiting and expensive computations such as summarization for a certain amount of messages are not excessively repeated
	- agent memory manager, that is responsible for these duties must keep track of which events are included in which compacted sumaries
	- prevents the original events to be needlessly sent to the LLM

Deciding when compaction is necessary:
- count-based triggers
	- once convo exceeds certain threshold, it gets summarized
	- usually "good enough"
- time-based triggers
	- lack of activity sets it off, and llm will summarize it
- event-based triggers
	- when topic changes or llm detects that the specific task or goal is met

- in essence we're trying to keep the most relevant information while keeping the context window for session transcripts as small as possible
# Memory
- sessions are the primary data source for generating memories
- memories are a key strategy for managing the size of the session
- **a memory is a condensed representation of all of the session data that is meant to preserve the most important context** - making the agent as useful for future interactions
- memories are persisted across sessions to provide a continuous user experience
- memory manager: decoupled service that provides the foundation for multi-agent interoperability
	- use framework-agnostic data structures, like simple strings and dictionaries

Robust memory system unlocks these capabilities:
- personalization
- context window management (session compaction using summarization)
- data mining across many users - can extract insights from the noise
- agent self-improvement and adaption

Creating, storing and utilizing memory is collaborative process. Each component has a distinct role to play
- User: provides raw source data for memories
- Agent: decides when and what to remember
	- basic architectures can be implemented so that memory is always retrieved and always triggered to be generated
	- in advanced architectures, memory can be a tool, where the agent decides when memory should be retrieved or generated
- Agent Framework (Google ADK, LangGraph): structure and tools for memory interaction
	- defines the developer logic of accessing conversation history and long-term storage
- The session storage (Agent Engine Sessions, Spanner, Redis): stores conversation of the session
- The Memory Manager (Agent Engine Memory Bank, Mem0, Zep): storage, retrieval, and compaction of memories
	- takes the potential memory identified by the agent and handles its entire lifecycle:
		- Extraction: takes key information from the source data
		- Consolidation: curates memories to merge duplicative entities
		- Storage: persists memory for persistent database
		- Retrieval: fetches relevant memories to provide context for new interactions
![[Pasted image 20260109130050.png]]
- developer can focus on agent's unique logic without having having to build the complex underlying infrastructure for memory persistence
- memory manager is not just a passive vector database
	- uses similarity search for retrieval
	- its core value lies in its ability to intelligently extract, consolidate and curate memories over time
- use managed memory services to handle the entire lifecycle of memory generation and storage

RAG vs memory management:
- RAG handles static external data while memory curates dynamic, user-specific context
- RAG makes an agent an expert on facts, memory makes it an expert on the user
- RAG is generally shared across all users, memory is scoped per-user to prevent data leaks
- Write patterns
	- Batch processing for RAG - triggered via an offline, administrative action
	- Event-based processing - Triggered at some cadence
		- end of every turn or session
		- memory as a tool (agent decides to generate memories)
- A truly intelligent agent needs both RAG for expert knowledge and memory for expert understanding of the user

## Types of memory
- An agent's memory can be categorized by the information is stored and how it was captured
- across al types of memories, memories are descriptive, not predictive
- a **memory** is an atomic piece of context that is returned by the memory manager and used by the agent as context
	- the schema and content and metadata

Content
- substance of the memory that was extracted from the source data
- framework-agnostic
- structured or unstructured data
	- structured data schema is usually defined by the developer, not a specific framework
	- unstructured memories are natural language descriptions that capture the essence of a longer interaction, event or topic

Metadata:
- provides context about the memory
- typically stored as a simple string
- can include unique identifier for the memory, identifiers for the "owner" of the memory, and labels describing the content or data source of the memory
### Types of information
- memories can be classified by the fundamental type of knowledge they represent
- declarative memories (knowing what)
	- facts, figures and events
	- whatever knowledge the agent can explicitly state or declare
	- general world knowledge and specific user facts
- procedural memories (knowing how)
	- knowledge of skills and workflows
	- demonstrates implicitly how to perform a task correctly
### Organization patterns
- three different patterns on how memories are organized
- Collections
	- multiple self-contained, natural language memories for a single user
	- can have multiple collections (each for single high level topics) in a single memory base
	- best for storing and searching through larger, less structured pool of information related to specific goals or topics
- Structured user profile
	- organizes memories as a set of core facts about a user
	- like a contact card that is continuously updated with relevant information
	- useful for quick lookups of essential factual information about a user
- Rolling summary
	- consolidates all info into a single, long memory
	- usually AI generated summaries of long sessions, preserving vital info while managing token count
	- represents a natural language summary of the entire user-agent relationship
### Storage architectures
- often stored in vector databases and/or knowledge graphs
- vector dbs
	- most common approach
	- enables retrieval based on semantic similarity rather than exact keywords
	- excels at retrieving unstructured, natural language memories where context and meaning are key
- knowledge graphs
	- memories as network of nodes, and relationships between memories as edges
	- good for structured relational queries and understanding complex connections within the data
- hybrid approach
	- you can use both structured knowledge graph and embed the entities of the knowledge graph into a vector db
### Creation mechanisms
- can also classify memories by how they were created
- Explicit memories: user gives explicit command to agent to remember something
- Implicit memories: agent infers and extracts information from the conversation without a direct command
- Internal memory: memory management that is built into the agent framework
- External memory: separate specialized service dedicated to memory management
	- agent framework makes API calls to this service to store, retrieve and process memories
	- also provides more sophisticated features like semantic search, entity extraction, and automatic summarization
### Memory scope
- User level scope
	- memories are tied to a specific user id and persist across all their sessions, allowing the agent to build a long term understanding of their preferences and history
- session-level scope
	- compaction of long conversations
	- creates a persistent record of insights extracted from a single session, so tokens can be saved
- application level scope
	- memories accessible by all users of an application
	- provide shared context
	- memories need to be sanitized of PII to prevent data leaks between users

### Multimodal memory
- describes how an agent handles non-textual information
- distinguish between the data the memory is derived from, and the data the memory is stored as
- Memory from a multimodal source
	- takes the multimodal content and transcribes a text description/summary about that to use as a memory
	- more common, easier to implement
- Memory containing multimodal content
	- stores the multimodal content itself as memory
	- harder to implement, not generally done
## Memory Generation: Extraction and Consolidation
- memory consolidation is decided using an LLM, think of it as LLM-driven ETL
- LLM intelligently decides when to add, update or merge memories
	- abstracts away the complexity of managing the database contents
![[Pasted image 20260109155010.png]]
General process of memory generation:
- Ingestion: client provides a source of raw data, typically a conversation history
- Extraction and Filtering
	- memory manager uses an LLM to extract meaningful content from the source data
	- LLM only extracts things related to a predefined topic definition (developer defined)
- Consolidation
	- uses an LLM to compare then new information with existing memories, and decides to one of the following
		- merge the new insight into a existing memory
		- delete an existing memory if invalid
		- create a new memory if topic is novel
- Storage
	- new or updated memory is persisted to a storage layer like a vector db or knowledge graph
### Memory Extraction deep-dive

The goal of memory extraction is to answer "**What information in the conversation is meaningful enough to become a memory?**"

- "meaningful" is defined entirely by the agent's purpose and use case
	- what might be meaningful for one use case might not be meaningful for another use case
- memory manager's LLM decides what to extract by following a set of programmatic guardrails and instructions - usually embedded in a system prompt
- **schema and template based extraction**
	- LM is given a predefined JSON output schema that it has to put the memories in from the inputted conversation history
	- uses features like structured output
- **natural language topic definitions**
	- LLM is guided by a simple naturall language description of the topic
- few-shot examples can "show" the LLM what information to extract using examples
	- includes several examples of input text and ideal, high-fidelity memory that should be extracted
	- effective for custom or nuanced topics that are difficult to describe with a schema or simple definition
- most memory managers work with common topics, but can refine further for custom topics
- the memory manager can receive a full, unedited conversation, but also can receive a rolling summary of the conversation

### Memory Consolidation deep dive
- most sophisticated stage in the memory lifecycle
	- transforms a collection of facts into a curated understanding of the user
- consolidation addresses fundamental problems from conversational data including
	- information duplication in memories
	- conflicting information in memories
	- information evolution
		- memories might evolve into complex, detailed versions of themselves
	- memory relevance decay
		- should prune old, stale and low confidence memories to keep the knowledge base relevant and efficient
		- can happen through instructing the LLM to defer to newer information during consolidation
		- or can happen through automatic deletion via time-to-live (TTL)

General workflow of consolidation:
- tries to retrieve existing memories that are similar to newly extracted memories
	- uses similarity search for this extraction of existing memories
- LM is presented with existing memories and new information. can choose to
	- update
	- create
	- delete/invalidate
- translates the LM's decision into a transaction that updates the memory store
### Memory Provenance
- memory provenance: a detailed record of a memory's origin and history
- we care about memory provenance primarily for the reason of figuring out how relevant, trustworthy and important a memory is
- we feed memory provenance into an LLM to decide whether a memory is trustworthy or not
![[Pasted image 20260109163914.png]]
- a single memory might be a blend of multiple data sources, and a source might be segmented into multiple memories
- agent must track key details for each source, such as origin (source type) and age (freshness)
	- these dictate the weight of each source during memory consolidation and during inference
- source type:
	- bootstrapped data: information preloaded from internal systems, such as a CRM
		- very high trust
		- helpful for cold-start problem (new user, no memories)
	- explicit user input
		- high trust
	- implicit user input
		- less trustworthy
	- tool output
		- generating memories from a tool output is generally not recommended
		- will go brittle and stale soon
		- better for short-term caching if necessary to keep around the information for a specific purpose

**Accounting for memory lineage during memory management**
- primary operational challenges when managing memories: conflict resolution and deleting derived data
- memory provenance allows the memory manager to establish a hierarchy of trust for its info sources
- when running into contradictions, the agent will use provenance in this way:
	- prioritizing the most trusted source
	- favoring recent information
	- looking for corroboration across multiple data points
- when a user revokes access to one data source, data derived from that source should also be removed
	- should regenerate the affected memories from scratch using only the remaining valid sources

confidence in a memory must be able to be dynamic
- must increase when multiple data sources provide consistent information
- must also be able to forget memories as well
	- time based decay: importance of a memory can decrease over time
	- low confidence: a memory that was created from weak inference and never corroborated by other sources
	- irrelevance: agent might determine older, trivial memories, though valid, might not be useful to remember

**Accounting for memory lineage during inference**
- memory confidence score is critical during inference time
- memories and their confidence scores should be injected into the prompt, enabling the LLM to assess information reliability and make more nuanced decisions
- not shown to the user directly
### Triggering memory generation
- when should memory generation be triggered?
	- session completion: at the end of a multi-turn session
	- turn cadence: running the process after a specified number of turns
	- real-time: after every single turn
	- explicit command: user command like "remember this"
- this is tradeoff between cost and fidelity
- frequent generation is fresh and detailed, but costly
- infrequent generation is cheap but risks creating lower-fidelity memories, as the LM must summarize a much larger block of conversation at once

**Memory as a Tool**
- allows the agent itself to decide when to create a memory
-  a tool is created with a description of what information might be meaningful enough to create a memory out of
- shifts the responsibility for identifying meaningful info from the external memory manager to the agent (the developer, YOU!)

**Background vs Blocking Operations**
- memory generation is an expensive operation that takes time to do
- should almost always be handled asynchronously as a background process
- after an agent sends its response to the user, the pipeline can run in parallel
### Memory Retrieval
- strategy for memory retrieval depends on how complex the data is and how memories are organized
	- for a structured user profile, retrieval is just a lookup for the entire user profile or a specific attribute
	- collection of memories it is far more complex
- the core challenge for complex retrieval is balancing memory usefulness within a strict latency budget
- they use
	- relevance: semantic similarity search
	- recency
	- importance: how important is this memory overall?
		- ex: the user's name or birthdate is ranked as highly important
			- we don't want this information to decay over time due to recency, so we add importance as well so that if we are choosing between retrieved memories, this filters near the top
- for applications where accuracy matters a lot
	- retrieval can use specialized retrievers that use reranking, query rewriting etc.
	- however, these methods are computationally expensive (latency), so use caching to cache expensive queries for subsequent identical requests
- ultimately, the best approach with retrieval starts with better memory generation
#### Timing for retrieval
When do we retrieve memories? What is the best way to know when to retrieve memories?
- Proactive Retrieval: memories are automatically loaded at the start of every turn using user query to retrieve relevant memories
	- latency for turns that don't require memory access, but can be cached to mitigate this cost
- Reactive retrieval
	- agent is given a tool to query its memory, deciding for itself when to retrieve context
	- more efficient and robust, but requires an additional LLM call, increasing cost and latency
	- agent may not know if relevant information exists to be retrieved
		- can be mitigated by making the agent aware of the types of memories available in tool's description
### Inference with Memories
- once memories retrieved, final step is to strategically place them into the model's context window
- critical process
- memories are primarily included in
	- the system prompt for global memories like a user profile
	- dialogue injection or memory as a tool for episodic memories that are immediately relevant to the conversation

**Including memories in the system prompt**:
- append memories to the system instructions
- keeps conversation history clean
- frames memories as foundational context for the entire interaction
- gives memories high authority, but risk of over influence, where the agent might relate every topic back to the memories in its core instructions
- limitations
	- framework must support dynamic construction of the system prompt before each LLM call
	- pattern is incompatible with "memory as a tool" because system prompt must be finalized before the LLM can decide to call a memory retrieval tool
	- poorly handles non-textual memories

**Including memories in the conversation history**:
- memories injected directly into the turn-by-turn dialogue
- either be placed before the convo history or after the latest user query
- considerations
	- might be noisy and increase token costs
	- dialogue injection: model might mistakenly treat a memory as something that was actually said in the conversation
	- need to be careful about the perspective of memories
		- if using user role and user-level memories, memories should be written in first person point of view
- retrieving memories via tool calls
	- message is included directly in the conversation as part of the tool output
### Procedural memories
- storing the how is not an information retrieval problem, it is a reasoning augmentation problem
- requires a completely separate algorithmic lifecycle
	- Extraction: requires a specialized prompt to distill a reusable strategy or playbook from a successful interaction
	- Consolidation: curates the workflow itself
		- integrates new successful methods with existing best practices
		- patches flawed steps in a known plan
		- prunes outdated or ineffective procedures
	- Retrieval: retrieves a plan of action
		- might have a completely different data schema than declarative memories
- similar to RLHF, but procedural memory provides a fast, online adaptation by dynamically injecting the correct playbook into the prompt
### Testing and Evaluation of memories
- requires verifying that an agent is remembering the right things (quality), it can find those memories when needed (retrieval) and that using those memories actually helps it accomplish its goals (task success)

**Memory generation quality metrics**: Typically measured by comparing the agent's generated memories against a manually created "golden set" of ideal memories
- precision
	- of all memories the agent created, what percentage are accurate and relevant?
	- high precision guards against an "over-eager" memory system that pollutes the knowledge base with irrelevant noise
- recall
	- of all relevant facts it should've remembered from the source, what percentage did it actually capture?
	- high recall guards against the agent missing critical information
- F1-score
	- harmonic mean of precision and recall, providing a single balanced measure of quality

**Memory retrieval performance metrics**: evaluates an agent's ability to find the right memory at the right time, considering the right memory exists
- Recall@K
	- when a memory is needed, is the correct one found within the top K retrieved memories
	- primary measure of a retrieval system accuracy
- Latency
	- retrieval is on hot path of agent response
	- entire retrieval process must execute within a strict latency budget (under 200ms)

**End-to End task success metrics**: Does the memory actually help the agent perform its job better
- often using LLM as judge to compare the agent's final output to a golden answer

- Evaluation is an engine for continuous improvement
- iterative process involves
	- establishing a baseline
	- analyzing failures
	- tuning the system
	- re-evaluating to measure the impact of the changes
- production readiness also depends on performance and latency
- generation and consolidation must have enough throughput to keep up with user demand
### Production considerations for Memory
- critical concerns for production include scalability, resilience and security

memory generation in production looks like:
- Agent pushes data
	- agent makes a non-blocking API call to the memory manager, pushing the raw source data to be processed
- Memory manager processes in the background
	- memory manager acknowledges the request and places the generation task in its own internal, managed queue
- Memories are persisted
	- The service writes the final memories (new, updates, deletions) to a db
	- for managed memory managers, storage is built in
- Agent retrieves memories
	- agent can query this memory store directly when it needs to retrieve context for a new user interaction

- ensures that failures in memory generation pipeline do not impact the user-facing application
- system must prevent deadlocks or race conditions when multiple events try to modify the same memory
- robust message queue is essential to buffer high volumes of events and prevent memory generation service from being overwhelmed
- should also have failure handling
	- if LLM call fails, should have retry mechanism
- should have multi-replication
### Privacy and security
- data isolation: memory must be strictly isolated at the user or tenant level
- use restrictive access control lists (ACL)
- redact any PII before filing documents that multiple users may use, such as procedural memories

# References
https://www.youtube.com/watch?v=zTxvGzpfF-g
https://drive.google.com/file/d/1C-HvqgxM7dj4G2kCQLnuMXi1fTpXRdpx/view
https://drive.google.com/file/d/1ENMUDzybOzxnycQQxNh5sE9quRd0s3Sd/view
https://drive.google.com/file/d/1JW6Q_wwvBjMz9xzOtTldFfPiF7BrdEeQ/view